{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "305f17a2",
   "metadata": {},
   "source": [
    "# Web Scraping Examples\n",
    "This notebook contains examples of web scraping using `requests`, `BeautifulSoup`, and `Selenium` as described in the provided PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9670693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import requests\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "# Ejemplo 1: Descargar un archivo usando requests\n",
    "def download_file():\n",
    "    url = \"http://www.mambiente.munimadrid.es/opendata/horario.txt\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open('horario.txt', 'wb') as output:\n",
    "            output.write(response.content)\n",
    "    return response.status_code\n",
    "\n",
    "# Ejemplo 2: Analizar datos descargados con csv y matplotlib\n",
    "def analyze_data():\n",
    "    path = 'horario.txt'\n",
    "    with open(path) as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        for row in readCSV:\n",
    "            if (row[0]+row[1]+row[2]=='28079004' and row[3]=='12'):\n",
    "                plt.title(\"Óxido de nitrógeno: \" + row[8] + \"/\" + row[7] + \"/\" + row[6])\n",
    "                hora = 0\n",
    "                desp = 9\n",
    "                vs = []\n",
    "                horas = []\n",
    "                while hora <= 23:\n",
    "                    if row[desp + 2*hora + 1] == 'V':\n",
    "                        vs.append(row[desp + 2*hora])\n",
    "                        horas.append(hora)\n",
    "                    hora += 1\n",
    "                plt.plot(horas, vs)\n",
    "                plt.show()\n",
    "\n",
    "# Ejemplo 3: Web scraping estático con BeautifulSoup\n",
    "def static_web_scraping():\n",
    "    html_content = '''\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "      <head>\n",
    "        <title>\n",
    "          Un mini ejemplo\n",
    "        </title>\n",
    "      </head>\n",
    "      <body>\n",
    "        <div id=\"date\"> Fecha 25/03/2035 </div>\n",
    "        <div id=\"content\"> Un poco de texto </div>\n",
    "      </body>\n",
    "    </html>\n",
    "    '''\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    print(soup.prettify())\n",
    "    print(soup.find(\"div\", id=\"date\").get_text())\n",
    "\n",
    "# Ejemplo 4: Web scraping dinámico con Selenium\n",
    "def dynamic_web_scraping():\n",
    "    driver = webdriver.Chrome()  # Ensure ChromeDriver is in the PATH\n",
    "    url = \"https://www1.sedecatastro.gob.es/CYCBienInmueble/OVCBusqueda.aspx\"\n",
    "    driver.get(url)\n",
    "    coord = driver.find_element_by_link_text(\"COORDENADAS\")\n",
    "    coord.click()\n",
    "    lat = driver.find_element_by_id(\"ctl00_Contenido_txtLatitud\")\n",
    "    lon = driver.find_element_by_id(\"ctl00_Contenido_txtLongitud\")\n",
    "    latitud = \"28.2723368\"\n",
    "    longitud = \"-16.6600606\"\n",
    "    lat.send_keys(latitud)\n",
    "    lon.send_keys(longitud)\n",
    "    datos = driver.find_element_by_id(\"ctl00_Contenido_btnDatos\")\n",
    "    datos.click()\n",
    "    # Add any additional steps to extract data as needed\n",
    "    driver.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f5e21",
   "metadata": {},
   "source": [
    "## Llamar a las funciones para probar los ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4604c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar a las funciones para probar los ejemplos (excepto download_file y dynamic_web_scraping que requieren acceso a la red y un navegador)\n",
    "static_web_scraping()\n",
    "# analyze_data()  # Run this after download_file() is executed successfully and horario.txt is available\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81409ad2",
   "metadata": {},
   "source": [
    "## Instrucciones de ejecución local\n",
    "1. **Instalar las dependencias**:\n",
    "```bash\n",
    "pip install requests beautifulsoup4 matplotlib selenium\n",
    "```\n",
    "Asegúrate de tener ChromeDriver instalado y en tu PATH. Puedes descargarlo desde [aquí](https://sites.google.com/a/chromium.org/chromedriver/downloads).\n",
    "\n",
    "2. **Ejecutar el notebook**:\n",
    "- Descarga el archivo `horario.txt` ejecutando `download_file()`.\n",
    "- Ejecuta `analyze_data()` para analizar los datos descargados.\n",
    "- Ejecuta `static_web_scraping()` para ver cómo funciona BeautifulSoup.\n",
    "- Ejecuta `dynamic_web_scraping()` para realizar web scraping dinámico con Selenium."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
